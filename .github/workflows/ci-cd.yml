name: ğŸš€ TechFood API - Deploy Only

on:
  push:
    branches:
      - "**"
  pull_request:
    branches:
      - "**"

env:
  NAMESPACE: techfood
  AWS_REGION: us-east-1

jobs:
  deploy-to-eks:
    name: ğŸš€ Deploy API to EKS
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}
      AWS_DEFAULT_REGION: us-east-1

    steps:
    - name: ğŸ“¥ Checkout code
      uses: actions/checkout@v3

    - name: ğŸ› ï¸ Setup kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'

    - name: ğŸ› ï¸ Setup Kustomize
      run: |
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
        sudo mv kustomize /usr/local/bin/

    - name: âš™ï¸ Configure AWS credentials (AWS Academy)
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
        aws-region: ${{ env.AWS_REGION }}
        mask-aws-account-id: false
        role-duration-seconds: 3600
        role-skip-session-tagging: true

    - name: ğŸ” Verify AWS credentials
      run: |
        echo "ğŸ” Verifying AWS credentials..."
        echo "ğŸ” Environment variables:"
        echo "AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID:0:10}..."
        echo "AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY:0:10}..."
        echo "AWS_SESSION_TOKEN: ${AWS_SESSION_TOKEN:0:20}..."
        echo "AWS_DEFAULT_REGION: $AWS_DEFAULT_REGION"

        aws sts get-caller-identity
        echo "ğŸ“‹ Checking AWS caller identity details..."
        aws sts get-caller-identity --query 'Arn' --output text
        echo "ğŸ“‹ Checking EKS cluster access..."
        aws eks describe-cluster --region ${{ env.AWS_REGION }} --name eks-techfood-terraform --query 'cluster.{Name:name,Status:status,Endpoint:endpoint}' --output table

    - name: ğŸ“‹ Update kubeconfig for EKS
      run: |
        echo "ğŸ“‹ Updating kubeconfig for EKS cluster..."
        aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name eks-techfood-terraform --alias eks-techfood
        echo "âœ… Kubeconfig updated successfully"

        # Test AWS token functionality directly
        echo "ğŸ” Testing AWS EKS get-token command directly..."
        aws eks get-token --cluster-name eks-techfood-terraform --region ${{ env.AWS_REGION }} || echo "âŒ Token generation failed"

        # Debug kubeconfig
        echo "ğŸ” Debug: Checking kubeconfig..."
        kubectl config view --minify
        echo "ğŸ” Debug: Current context..."
        kubectl config current-context

        # Create a simple test to isolate the issue
        echo "ğŸ” Testing AWS credentials with a simple command..."
        aws sts get-caller-identity || echo "âŒ AWS STS failed"

        # Test kubectl auth
        echo "ğŸ” Testing kubectl auth can-i..."
        kubectl auth can-i get pods --namespace=default || echo "âŒ kubectl auth failed"

        # Test basic connectivity with extended timeout
        echo "ğŸ” Testing cluster connectivity..."
        kubectl version --short --client || echo "âŒ kubectl client version failed"
        kubectl cluster-info --request-timeout=60s || echo "âŒ Cluster info failed - proceeding anyway"

    - name: ğŸ”„ Update image references
      run: |
        cd src/base

        # Update image reference to use Docker Hub
        DOCKERHUB_USER="${{ secrets.DOCKERHUB_USERNAME }}"

        # Use kustomize to set the correct image
        kustomize edit set image techfood-api=${DOCKERHUB_USER}/techfood-api:latest

        echo "ğŸ“‹ Updated image reference:"
        cat kustomization.yaml

    - name: ğŸš€ Deploy using base/kustomization.yaml
      run: |
        echo "ğŸš€ Deploying techfood-api using base/kustomization.yaml..."
        echo "ğŸ“¦ Using image: ${{ secrets.DOCKERHUB_USERNAME }}/techfood-api:latest"

        # Final AWS credentials test before deploy
        echo "ğŸ” Final credential check before deployment..."
        aws sts get-caller-identity

        # Generate and examine the final kustomize output
        echo "ğŸ“‹ Generating final kustomize output..."
        kustomize build src/base > /tmp/deployment.yaml
        echo "ğŸ“‹ Generated deployment manifest:"
        cat /tmp/deployment.yaml | head -50

        # Apply resources using kustomize from base directory with better error handling
        echo "ğŸ“‹ Deploying resources from src/base/kustomization.yaml..."
        if kustomize build src/base | kubectl apply -f - --validate=false; then
          echo "âœ… Deployment applied successfully"
        else
          echo "âŒ Deployment failed, trying individual resources..."
          # Fallback: Apply resources individually
          kubectl apply -f src/base/namespace.yaml --validate=false || echo "namespace may already exist"
          kubectl apply -f src/base/configmaps.yaml --validate=false
          kubectl apply -f src/base/secrets.yaml --validate=false
          kubectl apply -f src/base/pvc.yaml --validate=false
          kubectl apply -f src/base/techfood-api.yaml --validate=false
          kubectl apply -f src/base/hpa.yaml --validate=false
        fi

        echo "â³ Waiting for deployment rollout..."
        kubectl rollout status deployment/techfood-api -n ${{ env.NAMESPACE }} --timeout=300s || echo "âŒ Rollout status check failed, but deployment may still be successful"

    - name: âœ… Deployment Summary
      run: |
        echo "ğŸ‰ TechFood API deployed successfully!"
        echo "ğŸ·ï¸ Image: ${{ secrets.DOCKERHUB_USERNAME }}/techfood-api:latest"
        echo "ğŸ“… Deployed at: $(date)"
        kubectl get pods -l app.kubernetes.io/name=techfood-api -n ${{ env.NAMESPACE }}
